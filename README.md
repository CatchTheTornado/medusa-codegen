# Medusa Codegen

This is a Proof of Concept version of MedusaJS AI based code generation platform. The first use cases are build around import/export features supporting [all available Ollama open source models](https://ollama.com/library) (including LLama3, CodeLlama ...) and GPT-4o as an option. It can integrate MedusaJS with literally anything which could be accesed via TypeScript code. No coding skill required.

LLM aspect is pretty import in this project because all the code - for now Import and Export Operations are **generated by AI**. You only need to prompt the description of your data input our output and we'll do the rest - generating the suitable importer or exporter code that you can run anytime.

## Installation

To install the required dependencies, run the following command:

```
docker-compose up
```

It may take a while because this command is downloading the latest LLama3 distribution (4.7GB). Then it's also installing MedusaJS, Postgres DB and so on.

## Usage

To run the application in development mode, use the following command:

```
docker-compose run npm run dev
```

This command uses `nodemon` and `tsx` to automatically restart the application whenever changes are made to the source files.

You can play with example prompts from: `/src/platforms/medusa/example-prompts` folder. 
You can change the LLM model by switching the `OLLAMA_MODEL` env variable to any of [those supported](https://ollama.com/library).

## Ollama Web-UI

There's a Ollama WebUI instance defined in the default `docker-compose` file and after all is up - it should be available on `http://localhost:8081`

## Medusa JS instance

There's also a Medusa test instance defined in the `docker-compose` file - which is by default run on `http://localhost:9000/app/login`

To add a default admin user please run:

```
docker-compose exec medusa npx medusa user -e some@email.com -p some-password 
```

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.
```
